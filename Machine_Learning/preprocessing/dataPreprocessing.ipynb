{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@Author:Nagashree C R<br>\n",
    "@Date:30-09-2024<br>\n",
    "@Last modified By:Nagashree C R<br>\n",
    "@Last Modified Date:30-09-2024<br>\n",
    "@Title: Applied different data preprocessing steps :<br>\n",
    "a. Handling missing data <br>\n",
    "b. Handling categorical data <br>\n",
    "c. Split the dataset into training set and test set <br>\n",
    "d. Feature scaling <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Task1:Classify the problems as supervised, unsupervised, reinforcement or semi supervised "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers and Reasons:**\n",
    "\n",
    "<h4><b>a.</b> Spam filtering: Is an email spam or not</h4>\n",
    "<p>Answer: Supervised Learning</p>\n",
    "<p>Reason: Classifies emails based on labeled examples of spam and non-spam.</p>\n",
    "\n",
    "<h4><b>b.</b> Given a list of customers and information about them, discover groups of similar users.</h4>\n",
    "<p>Answer: Unsupervised Learning</p>\n",
    "<p>Reason: Identifies patterns in data without labeled outcomes.</p>\n",
    "\n",
    "<h4><b>c.</b> Robotics: A robot is in a maze, and it needs to find a way out.</h4>\n",
    "<p>Answer: Reinforcement Learning</p>\n",
    "<p>Reason: Learns to navigate through feedback based on its actions.</p>\n",
    "\n",
    "<h4><b>d.</b> Training an AI for a complex game such as Civilization or Dota</h4>\n",
    "<p>Answer: Reinforcement Learning</p>\n",
    "<p>Reason: Learns strategies through trial and error while playing the game.</p>\n",
    "\n",
    "<h4><b>e.</b> Anomaly detection: Given measurements from sensors in a manufacturing facility, identify anomalies.</h4>\n",
    "<p>Answer: Unsupervised Learning (or Semi-Supervised)</p>\n",
    "<p>Reason: Finds unusual patterns without labeled examples.</p>\n",
    "\n",
    "<h4><b>f.</b> Discover patterns in data such as whenever it rains, people tend to stay indoors.</h4>\n",
    "<p>Answer: Unsupervised Learning</p>\n",
    "<p>Reason: Identifies relationships in data without specific labels.</p>\n",
    "\n",
    "<h4><b>g.</b> Given information about a house, predict its price</h4>\n",
    "<p>Answer: Supervised Learning</p>\n",
    "<p>Reason: Uses labeled data (features and prices) for prediction.</p>\n",
    "\n",
    "<h4><b>h.</b> Netflix: Given a user and a movie, predict the rating the user is going to give to the movie</h4>\n",
    "<p>Answer: Supervised Learning</p>\n",
    "<p>Reason: Uses historical data to predict future ratings based on features.</p>\n",
    "\n",
    "<h4><b>i.</b> Given an image, output which objects are present in the image</h4>\n",
    "<p>Answer: Supervised Learning</p>\n",
    "<p>Reason: Requires labeled images to train a model for object identification.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Task1:Data Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the URL with the appropriate path to the CSV file\n",
    "url = r\"C:\\Users\\ASHAY\\OneDrive\\Desktop\\bridgelabz\\final_ML\\ML_Programs\\Machine_Learning\\preprocessing\\dataPreprocessing.csv\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape   # 10 rows and 4 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>b<b>. Handling categorical data</h2>\n",
    "Separating the Independent variable and dependent variable values from the dataset\n",
    "          x+y=z          x+z=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data[['Country','Age','Salary']].values   # Indipendent variables\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['No'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['No'],\n",
       "       ['Yes'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['Yes']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data[['Purchased']].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>a</b>. Handling missing data \n",
    "Handling missing data because this values are leakes the data while training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "\n",
    "imputer = imputer.fit(x[:,1:3])\n",
    "x[:,1:3]=imputer.transform(x[:,1:3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the categorial data into numerical\n",
    "    converting country column into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable_encode_x = LabelEncoder()\n",
    "x[:,0] = lable_encode_x.fit_transform(x[:,0])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding for country column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotEncoder = OneHotEncoder()\n",
    "onehotEncoder.fit_transform(data.Country.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding for Purchased Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASHAY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lablede_encoder_y = LabelEncoder()\n",
    "y=lablede_encoder_y.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><b>c.<b> Split the dataset into training set and test set </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 40.0, 63777.77777777778],\n",
       "       [0, 37.0, 67000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [0, 44.0, 72000.0],\n",
       "       [0, 35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 30.0, 54000.0],\n",
       "       [1, 50.0, 83000.0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>d<b>.Feature scaling  </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13483997,  0.26306757,  0.12381479],\n",
       "       [-0.94387981, -0.25350148,  0.46175632],\n",
       "       [ 1.21355975, -1.97539832, -1.53093341],\n",
       "       [ 1.21355975,  0.05261351, -1.11141978],\n",
       "       [-0.94387981,  1.64058505,  1.7202972 ],\n",
       "       [ 1.21355975, -0.0813118 , -0.16751412],\n",
       "       [-0.94387981,  0.95182631,  0.98614835],\n",
       "       [-0.94387981, -0.59788085, -0.48214934]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -1.],\n",
       "       [ 0.,  1.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = sc.fit_transform(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocesssing steps is over now the model is ready we can apply the machine learnig algorithem on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>e</b>. Handling missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country      0\n",
      "Age          1\n",
      "Salary       1\n",
      "Purchased    0\n",
      "dtype: int64\n",
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "5   France  35.0  58000.0       Yes\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data.isnull().sum())\n",
    "data_cleaned = data.dropna() #Dropping rows with missing values\n",
    "print(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Traversing  each column to fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after filling:\n",
      "Country      0\n",
      "Age          0\n",
      "Salary       0\n",
      "Purchased    0\n",
      "dtype: int64\n",
      "   Country        Age        Salary Purchased\n",
      "0   France  44.000000  72000.000000        No\n",
      "1    Spain  27.000000  48000.000000       Yes\n",
      "2  Germany  30.000000  54000.000000        No\n",
      "3    Spain  38.000000  61000.000000        No\n",
      "4  Germany  40.000000  63777.777778       Yes\n",
      "5   France  35.000000  58000.000000       Yes\n",
      "6    Spain  38.777778  52000.000000        No\n",
      "7   France  48.000000  79000.000000       Yes\n",
      "8  Germany  50.000000  83000.000000        No\n",
      "9   France  37.000000  67000.000000       Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for column_name in data.columns:\n",
    "\n",
    "    if data[column_name].dtype in ['int64', 'float64']:  # Numerical columns\n",
    "        data[column_name] = data[column_name].fillna(data[column_name].mean())\n",
    "\n",
    "    elif data[column_name].dtype == 'object':  # Categorical columns\n",
    "        data[column_name] = data[column_name].fillna(data[column_name].mode()[0])\n",
    "\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Display the filled DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>f<b>. Handling categorical data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded DataFrame:\n",
      "    Age        Salary  Country_Germany  Country_Spain  Purchased_Yes\n",
      "0  44.0  72000.000000            False          False          False\n",
      "1  27.0  48000.000000            False           True           True\n",
      "2  30.0  54000.000000             True          False          False\n",
      "3  38.0  61000.000000            False           True          False\n",
      "4  40.0  63777.777778             True          False           True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "print(\"\\nEncoded DataFrame:\")\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>f.<b> Split the dataset into training set and test set </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8, 4) (8,)\n",
      "Test set shape: (2, 4) (2,)\n",
      "X_train:\n",
      "          Age        Salary  Country_Germany  Country_Spain\n",
      "5  35.000000  58000.000000            False          False\n",
      "0  44.000000  72000.000000            False          False\n",
      "7  48.000000  79000.000000            False          False\n",
      "2  30.000000  54000.000000             True          False\n",
      "9  37.000000  67000.000000            False          False\n",
      "4  40.000000  63777.777778             True          False\n",
      "3  38.000000  61000.000000            False           True\n",
      "6  38.777778  52000.000000            False           True\n",
      "X_test:\n",
      "     Age   Salary  Country_Germany  Country_Spain\n",
      "8  50.0  83000.0             True          False\n",
      "1  27.0  48000.0            False           True\n",
      "y_train:\n",
      " 5     True\n",
      "0    False\n",
      "7     True\n",
      "2    False\n",
      "9     True\n",
      "4     True\n",
      "3    False\n",
      "6    False\n",
      "Name: Purchased_Yes, dtype: bool\n",
      "y_test:\n",
      " 8    False\n",
      "1     True\n",
      "Name: Purchased_Yes, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "X = data_encoded.drop('Purchased_Yes', axis=1)  # labels\n",
    "y = data_encoded['Purchased_Yes']  # Target variable\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Optionally, display the first few rows of the training set\n",
    "\n",
    "# Display results\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"y_train:\\n\", y_train)\n",
    "print(\"y_test:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>g<b>.Feature scaling  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8, 4) (8,)\n",
      "Test set shape: (2, 4) (2,)\n",
      "\n",
      "First few rows of the scaled training set:\n",
      "[[-0.7529426  -0.62603778 -0.57735027 -0.57735027]\n",
      " [ 1.00845381  1.01304295 -0.57735027 -0.57735027]\n",
      " [ 1.79129666  1.83258331 -0.57735027 -0.57735027]\n",
      " [-1.73149616 -1.09434656  1.73205081 -0.57735027]\n",
      " [-0.36152118  0.42765698 -0.57735027 -0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()  # or MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train_scaled.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test_scaled.shape, y_test.shape)\n",
    "\n",
    "# Optionally, display the first few rows of the scaled training set\n",
    "print(\"\\nFirst few rows of the scaled training set:\")\n",
    "print(X_train_scaled[:5])  # Displaying the first 5 rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
